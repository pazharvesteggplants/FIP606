{
  "hash": "0adae4fd3e544ea6cbf9f4d7f0f20cc9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Análisis de Modelo Mixto, Correlación y Regresión Linear.\"\nformat: html\neditor: visual\n---\n\n\n## Pudrición de maíz.\n\nCada híbrido está dentro de cada bloque, el bloque se aleatorizó dentro de cada bloque.\n\nSe sortean los tratamientos del híbrido y los del método.\n\nSe sortean estos híbridos dentro de cada bloque.\n\nEs una parcela subdivida. ¿Cuándo es una parcela sub-sub dividida? Cuando hay 3 factores.\n\nNuestro modelo estadístico va a ser diferente, no es híbrido vs método+ bloque, se debe utilizar el valor b o utilizar un modelo mixto (mixtura entre un factor fijo y uno aleatorio). Ese es el modelo mixto, es un paquete diferente para estructurar esta situación (efecto aleatorio del híbrido).\n\n## Parcela subdividida\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(DHARMa)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(emmeans)\nmilho <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759')\n```\n:::\n\n\n## Index\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho |>\n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, alpha=0.2)+\n  facet_wrap(~hybrid)+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color = 'pink')\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n\nmilho<-milho|>\n  mutate(block = as.factor(block))\nmix2<- lmer(index ~ hybrid*method + block+\n              (1|block/hybrid), data = milho)\n\nanova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 262.548  52.510  3.1194\nmethod           1  79.053  79.053  4.6963\nblock            3   3.630   1.210  0.0719\nhybrid:method    5 266.064  53.213  3.1612\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(car)\n```\n:::\n\n\n1\\|block/hybrid indica la función (con efecto aleatorio). El resultado para la interacción entre híbrido y method es significativa.\n\n### Premisas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.635).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n\n\n:::\n\n```{.r .cell-code}\nsimulate_residuals(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimulated residuals from a model of class `lmerMod` based on 250\n  simulations. Use `check_residuals()` to check uniformity of residuals or\n  `residuals()` to extract simulated residuals. It is recommended to refer\n  to `?DHARMa::simulateResiudals` and `vignette(\"DHARMa\")` for more\n  information about different settings in particular situations or for\n  particular models.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n:::\n\n\n# Test de comparar medias\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_milho <- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho2 <- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\n\ncld(medias_milho, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.4 8.13 1022     3.49     35.4  A    \n 30K64      20.6 8.13 1022     4.59     36.5  A    \n 30F53 YH   24.6 8.13 1022     8.64     40.6  AB   \n 30F53 HX   25.3 8.13 1022     9.32     41.2  AB   \n 30S31YH    32.5 8.13 1022    16.54     48.5  AB   \n 30S31H     38.1 8.13 1022    22.14     54.1   B   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.2 8.13 1022     3.22     35.1  A    \n 30K64      21.5 8.13 1022     5.54     37.5  A    \n 30F53 HX   25.0 8.13 1022     9.04     41.0  A    \n 30F53 YH   26.2 8.13 1022    10.29     42.2  A    \n 30S31H     26.5 8.13 1022    10.54     42.5  A    \n 30S31YH    26.6 8.13 1022    10.69     42.6  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho2, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     25.0 8.13 1022     9.04     41.0  A    \n pin      25.3 8.13 1022     9.32     41.2  A    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      24.6 8.13 1022     8.64     40.6  A    \n silk     26.2 8.13 1022    10.29     42.2  A    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      20.6 8.13 1022     4.59     36.5  A    \n silk     21.5 8.13 1022     5.54     37.5  A    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.5 8.13 1022    10.54     42.5  A    \n pin      38.1 8.13 1022    22.14     54.1   B   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.6 8.13 1022    10.69     42.6  A    \n pin      32.5 8.13 1022    16.54     48.5  A    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     19.2 8.13 1022     3.22     35.1  A    \n pin      19.4 8.13 1022     3.49     35.4  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(Hmisc)\n\nindex <- milho |>\n  ggplot(aes(hybrid, index))+\n  geom_jitter(width = 0.05, color = \n                \"gray\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size = 0.5, color = \n                 \"red\", alpha = 0.5)\nindex\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nyield <- milho |>\n  ggplot(aes(hybrid, yield))+\n  geom_jitter(width = 0.05, color = \n                \"gray\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size = 0.5, color = \n                 \"red\", alpha = 0.5)\nlibrary(ggplot2)\nlibrary(Hmisc)\n\nyield <- milho |>\n  ggplot(aes(hybrid, yield))+\n  geom_jitter(width = 0.05, color = \n                \"gray\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size = 0.5, color = \n                 \"red\", alpha = 0.5)\n```\n:::\n\n\n![](images/clipboard-1362719507.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\nmilho |> \n  ggplot(aes(method, index))+\n  geom_jitter(width =0.1, alpha = 0.2)+\n  facet_wrap(~ hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", size \n               = 0.5, color = \"purple\")\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-8-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias_milho <- emmeans(mix2,\n                        ~hybrid | method,\n                        type= 'response'\n                        )\nmedias_milho <- emmeans(mix2,\n                        ~method | hybrid,\n                        type= 'response'\n                        )\nlibrary(multcomp)\ncld(medias_milho)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     25.0 8.13 1022     9.04     41.0  1    \n pin      25.3 8.13 1022     9.32     41.2  1    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      24.6 8.13 1022     8.64     40.6  1    \n silk     26.2 8.13 1022    10.29     42.2  1    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      20.6 8.13 1022     4.59     36.5  1    \n silk     21.5 8.13 1022     5.54     37.5  1    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.5 8.13 1022    10.54     42.5  1    \n pin      38.1 8.13 1022    22.14     54.1   2   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.6 8.13 1022    10.69     42.6  1    \n pin      32.5 8.13 1022    16.54     48.5  1    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     19.2 8.13 1022     3.22     35.1  1    \n pin      19.4 8.13 1022     3.49     35.4  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     25.0 8.13 1022     9.04     41.0  1    \n pin      25.3 8.13 1022     9.32     41.2  1    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      24.6 8.13 1022     8.64     40.6  1    \n silk     26.2 8.13 1022    10.29     42.2  1    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      20.6 8.13 1022     4.59     36.5  1    \n silk     21.5 8.13 1022     5.54     37.5  1    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.5 8.13 1022    10.54     42.5  1    \n pin      38.1 8.13 1022    22.14     54.1   2   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.6 8.13 1022    10.69     42.6  1    \n pin      32.5 8.13 1022    16.54     48.5  1    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     19.2 8.13 1022     3.22     35.1  1    \n pin      19.4 8.13 1022     3.49     35.4  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmix3 <- lmer(yield ~ hybrid *method + block + (1|block/hybrid), data = milho)\n\n(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: yield ~ hybrid * method + block + (1 | block/hybrid)\n   Data: milho\nREML criterion at convergence: 577.4931\nRandom effects:\n Groups       Name        Std.Dev.\n hybrid:block (Intercept) 1365.0  \n block        (Intercept)  666.3  \n Residual                  640.0  \nNumber of obs: 48, groups:  hybrid:block, 24; block, 4\nFixed Effects:\n              (Intercept)             hybrid30F53 YH  \n                  11404.6                    -1800.0  \n              hybrid30K64               hybrid30S31H  \n                    467.5                    -3089.5  \n            hybrid30S31YH              hybridBG7049H  \n                  -3371.5                      762.5  \n               methodsilk                     block2  \n                  -1220.0                    -1251.2  \n                   block3                     block4  \n                   -181.8                      644.4  \nhybrid30F53 YH:methodsilk     hybrid30K64:methodsilk  \n                   1023.5                      -94.0  \n  hybrid30S31H:methodsilk   hybrid30S31YH:methodsilk  \n                   2287.0                     1660.8  \n hybridBG7049H:methodsilk  \n                   2083.3  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 2 lme4 warnings \n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.211).\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias_milho <- emmeans(mix2,\n                        ~hybrid | method,\n                        type= 'response')\nmedias_milho <- emmeans(mix2,\n                        ~method | hybrid,\n                        type= 'response')\nlibrary(multcomp)\ncld(medias_milho)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     25.0 8.13 1022     9.04     41.0  1    \n pin      25.3 8.13 1022     9.32     41.2  1    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      24.6 8.13 1022     8.64     40.6  1    \n silk     26.2 8.13 1022    10.29     42.2  1    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      20.6 8.13 1022     4.59     36.5  1    \n silk     21.5 8.13 1022     5.54     37.5  1    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.5 8.13 1022    10.54     42.5  1    \n pin      38.1 8.13 1022    22.14     54.1   2   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.6 8.13 1022    10.69     42.6  1    \n pin      32.5 8.13 1022    16.54     48.5  1    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     19.2 8.13 1022     3.22     35.1  1    \n pin      19.4 8.13 1022     3.49     35.4  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     25.0 8.13 1022     9.04     41.0  1    \n pin      25.3 8.13 1022     9.32     41.2  1    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      24.6 8.13 1022     8.64     40.6  1    \n silk     26.2 8.13 1022    10.29     42.2  1    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      20.6 8.13 1022     4.59     36.5  1    \n silk     21.5 8.13 1022     5.54     37.5  1    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.5 8.13 1022    10.54     42.5  1    \n pin      38.1 8.13 1022    22.14     54.1   2   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.6 8.13 1022    10.69     42.6  1    \n pin      32.5 8.13 1022    16.54     48.5  1    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     19.2 8.13 1022     3.22     35.1  1    \n pin      19.4 8.13 1022     3.49     35.4  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n# Importar datos de arroz\n\n\n::: {.cell}\n\n```{.r .cell-code}\narroz<-gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555')\n```\n:::\n\n\nSi se inocula una semilla de arroz de 0 a 48%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\narroz |>\n  ggplot(aes(trat, nplants),theme_classic())+\n  geom_point(width = 0.1, alpha=0.2)+\n  facet_wrap(~exp)+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color = 'pink')+\n  geom_smooth(method = lm, se=FALSE)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp1 <- arroz |>\n  filter(exp==1)\nexp1 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n   geom_smooth(se=FALSE)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n# Modelo de regresión linear simple:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(nplants ~ trat,\n          data= exp1)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n\n\n:::\n:::\n\n\nLa hipotesis nula dice que el coeficiente de regresión es igual a 0 (no tiene efecto). Para cada 1% de inóculo se reduce 0,24. Como el valor p fue mayor que 0,05, no rejecta H0, entonces no tiene efecto.\n\n### Experimento 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- arroz |>\n  filter(exp==2)\nexp2 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n   geom_smooth(se=FALSE)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlm2 <- lm(nplants ~ trat,\n          data= exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n\n### Experimento 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3 <- arroz |>\n  filter(exp==3)\nexp3 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n   geom_smooth(se=FALSE)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlm3 <- lm(nplants ~ trat,\n          data= exp3)\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(residuals(lm3))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(lm1))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-16-3.png){width=672}\n:::\n:::\n\n\nAdjusted R-squared: 0,59 de y explica x en un 59%, el restante no se conoce.\n\n# GLM y AIC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm1 <- glm(nplants ~ trat, family = 'gaussian',\n            data = exp1)\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 202.0045\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2 <- glm(nplants ~ trat, family = 'gaussian',\n            data = exp2)\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2b <- glm(nplants ~ trat, family = 'poisson',\n            data = exp2)\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.2353\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3 <- glm(nplants ~ trat, family = 'gaussian',\n            data = exp3)\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 185.0449\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3b <- glm(nplants ~ trat, family = 'poisson',\n            data = exp3)\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nglm3 <- glmer(nplants ~ trat+ (trat| exp), family = 'gaussian',\n            data = arroz)\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: arroz\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 592.8402\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3b <- glmer(nplants ~ trat+ (trat| exp), family = poisson(link = log),\n            data = arroz)\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: arroz\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 660.7282\n```\n\n\n:::\n:::\n\n\n# Moho blanco en soya\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(r4pde)\n\nwm<- WhiteMoldSoybean\nwm |>\n  ggplot(aes(inc,yld))+\n  geom_point()+\n  facet_wrap(~study)+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1<- lm(yld ~ inc,\n           data= wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n\n\n:::\n:::\n\n\n#Se tienen 3299 kg/h de produccion al haber incidencia cero\n\n#Se disminuye por 9.2 por cada porcentual aumentado.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm |> \n  ggplot(aes(inc, yld,\n             #group = factor(study)\n             color = factor(study)\n             ))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  #theme_minimal()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmofo2<- wm%>%\n  group_by(study) |>\n  do(tidy(lm(.$yld ~ .$inc),conf.int=TRUE))\nmofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\ndf <- mofo2 |> filter (term == '.$inc')\nmean (df$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -19.52932\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_all <- wm%>%\n  group_by(study) |> \n  do(broom::tidy(lm(.$yld ~ .$inc), conf.int=TRUE))\nfit_all\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\np3 <- fit_all |> \n  filter(term == \"(Intercept)\") |> \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Intercept\", y = \"Frequency\")\n\np4 <- fit_all |> \n  filter(term == \".$inc\") |> \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\n\nlibrary(patchwork)\np3 | p4\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmofo3 <- lmer(yld~inc + (inc|study), data = wm,\n              REML= F)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(>Chisq)    \ninc 141.09  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nconfint(mofo3, method= 'Wald')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n```\n\n\n:::\n:::\n\n\nAqui se ve que el intercepto es de 3255 kg/h al haber 0 incidencia y cada porcentaje de incidencia aumentado, se pieden 17,23 kg/ha\n\n# Correlacion linear\n\nPodemos escoger modelos que pasan más próximos a todos los puntos, por lo que algunas regresiones estadísticas tienen diferentes modelos que pueden ser escogidos (PE regresiones no lineares).\n\nCrecimiento micelial / dosis cuál es la dosis que inhibe el 50% del crecimiento micelial, podemos hacer una comparación entre diferentes isolados fúngicos. Depende de la respuesta que nosotros modelamos.\n\nCorrelaciones: Es una asociacion entre 2 variables, también puede ser una disociación.\n\nEl incremento de una variable A y B, esta asociación en caso de que ambos datos aumenten, su relación es positiva.\n\nEntre más disaciociada(dispersa), esta se vuelve más cercana.\n\nCorrelación de pearson: 0 -1\n\nCuanto más disperson, menor el número de correlación.\n\nUna relación de causa efecto (uno aumenta y otro disminuye), como por ejemplo cuando una enfermedad aumenta y la productividad disminuye, puede tener una correlación negativa.\n\nLa regresión también se puede hacer también entre dos variables.\n\nR\\^2 = Al hacer la raíz de este resultado, siempre da menor a r. R2 es el coeficiente de determinación. Cuánto explica x a y.\n\nr Es la fuerza de asociación entre x e y\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\np1 <- img |> \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\np2 <- img |> \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\nimg |> \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |> \n  ggplot(aes(method, value))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 + p2\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nimg2 <- img |> \n  dplyr::select(Assess, LeafDoctor, ImageJ)\n\nlibrary(AgroR)\ncorgraph(img2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(img$Assess, img$LeafDoctor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  img$Assess and img$LeafDoctor\nt = 31.119, df = 68, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n```\n\n\n:::\n:::\n\n\nEn este caso, la conclusión el assess es el programa estándar para que de una relación buena, si podemos sustituir el assess con otros datos, igualmente podemos recibir nuevas relaciones causa efecto por medio de respuestas/métodos diferentes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(img$Assess, img$LeafDoctor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9666367\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(corrplot)\ncor_img2 <- cor(img2)\ncorrplot(cor_img2, method = 'number', type = \"lower\")\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nNos da colores de los numeros dentro de la relacion y la matriz.\n\nAhora trabajemos con otro conjunto de datos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor_img2 <- cor(img2)\ncorrplot(cor_img2, method = 'number', type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncampo <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 <- campo |> \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nUn problema que tenemos en campo, es que tenemos 2 enfermedades y queremos saber cual esta mas relacionada con la produccion.\n\nEn esta podemos ver que el DFC influye mas y donde hay DFC hay ferrugem pues estan correlacionadas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(campo$PROD, campo$DFC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  campo$PROD and campo$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(campo$PROD, campo$FER)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  campo$PROD and campo$FER\nt = -4.3949, df = 30, p-value = 0.0001277\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7999565 -0.3544981\nsample estimates:\n       cor \n-0.6258321 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncampo |>\n  ggplot(aes(DFC, PROD))+\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n# Modelo cuadrático de regresión linear.\n\nVamos a comparar los métodos linear y con el cuadrático.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- arroz |> \n  dplyr::filter(exp == 2)\n\nexp2 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n # stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color = \"black\",\n #              alpha = 0.5)+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              formula = y ~poly(x,2),\n              color = \"black\")+\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n## Primer orden (Modelo linear)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm2 <- lm(nplants ~trat,\n          data = exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(residuals(lm2))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n\n```{.r .cell-code}\nAIC(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2$trat2 <- exp2$trat^2\n\nlm3 <- lm(nplants ~trat + trat2,\n          data = exp2)\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,\tAdjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(residuals(lm3))\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n\n```{.r .cell-code}\nAIC(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 193.1284\n```\n\n\n:::\n:::\n\n\nConclusion: EL r2 se explica mejor con la regresion cuadratica que con la linear.\n\nSegun AIC tambien el modelo cuadratico explica mejor la variacion (diferencia de 43% a 49%), entre menor es mejor,\n\nY= 66,3 - 1,77 x TRAT + 0,02 x TRAT\\^2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(exp2, polynomial(trat, nplants, grau = 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(>|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n\nSe puede ver los intervalos de confianza para cada punto, ajustando segun lo que calculo abajo, para dar un R\\^2.\n\ngrau 1 = linear.\n\nGrau 2= cuadratico, modelino curvilinear.\n\ngrau 3 = cubica, no tiene una explicacion biologica por lo que casi no se utiliza para esta aumentar entre dos tractos.\n\n# Datos de sensibilidad de fungicidas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npyra <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\npyra2 <- pyra |>\n  group_by(code, state, dose) |> \n  summarise(mean_germination = mean(germination))\n\npyra2|> \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\n## Filtrar Isolado 186\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(drc)\n\nisolado186 <- pyra2 |> \n   filter(code == \"186\")\n\ndrc1 <- drm(mean_germination ~ dose, data = isolado186,\n            fct = W1.3())\n\nAIC(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 20.97861\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(drc1)\n```\n\n::: {.cell-output-display}\n![](aula9_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\nSi la estimativa fuera mas alta, es mas sensible al fungicida.\n\nSi la estimativa (Estimate) fuera mas baja, es menos sensible al fungicida.\n\nEntre menor es el AIC, mejor.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}