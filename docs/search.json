[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bem-vindo ao meu website!",
    "section": "",
    "text": "Instagram\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Email\n  \n\n\n\n\nBem-vindo ao meu website!"
  },
  {
    "objectID": "aula8.html",
    "href": "aula8.html",
    "title": "aula 8",
    "section": "",
    "text": "Se va a trabajar análisis en una base de datos con 3 variables, por lo que se hará un anova para todas juntas y una para cada una.\nVamos a tener, un tratamiento, un bloco y un local (el local se puede eliminar al tener solo 1). Al ver que todos son números, hay que colocarlos como si fuera un factor.\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(performance)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(DHARMa)\nsoja&lt;-gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711')\n\nsoja&lt;- soja |&gt;\n  mutate(TRAT=as.factor(TRAT),\n         BLOCO=as.factor(BLOCO))"
  },
  {
    "objectID": "aula8.html#visualización",
    "href": "aula8.html#visualización",
    "title": "aula 8",
    "section": "Visualización",
    "text": "Visualización\n\ndfc &lt;- soja |&gt;\n  ggplot(aes(TRAT,DFC))+\n  geom_jitter(width = 0.05, color='gray70')+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color= 'black', alpha=0.5)\ndfc\n\n\n\n\n\n\n\n\n\nfer &lt;- soja |&gt;\n  ggplot(aes(TRAT,FER))+\n  geom_jitter(width = 0.05, color='gray70')+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color= 'black', alpha=0.5)\nfer\n\n\n\n\n\n\n\n\n\nprod &lt;- soja |&gt;\n  ggplot(aes(TRAT,PROD))+\n  geom_jitter(width = 0.05, color='gray70')+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color= 'black', alpha=0.5)\nprod\n\n\n\n\n\n\n\n\n\nsum&lt;- prod+fer+dfc\nsum\n\n\n\n\n\n\n\n\nQueremos explorar los efectos de los tratamientos en cada variable, comparando el tratamiento, viendo si existen diferencias entre cada tratamiento y tambien la variabilidad entre ellos.\nViendo cuales son las premisas de anova"
  },
  {
    "objectID": "aula8.html#anova-dfc",
    "href": "aula8.html#anova-dfc",
    "title": "aula 8",
    "section": "Anova DFC",
    "text": "Anova DFC\nEsto es factorial, sin embargo en vez de cruzarse, se adicionan.\nSe ve que los tratamientos se definen con diferencia altamente significativa\n\naov_dfc&lt;-lm(DFC~ TRAT + BLOCO,\n             data=soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nmedias_dfc&lt;- emmeans(aov_dfc, ~TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_dfc, Letters=LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula8.html#anova-fer",
    "href": "aula8.html#anova-fer",
    "title": "aula 8",
    "section": "Anova FER",
    "text": "Anova FER\n\nlibrary (MASS)\n\nb&lt;-boxcox(lm(soja$FER~1))\n\n\n\n\n\n\n\n#calcular lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\n#hacer la formula\nsoja$FER2 &lt;- (soja$FER ^ lambda -1) /lambda\naov_fer&lt;-lm(log(FER2)~ TRAT + BLOCO,\n             data=soja)\naov_fer\n\n\nCall:\nlm(formula = log(FER2) ~ TRAT + BLOCO, data = soja)\n\nCoefficients:\n(Intercept)        TRAT2        TRAT3        TRAT4        TRAT5        TRAT6  \n   -0.41324     -0.06635     -0.14406     -0.18962     -0.16696     -0.19729  \n      TRAT7        TRAT8       BLOCO2       BLOCO3       BLOCO4  \n   -0.15544     -0.14777     -0.04781     -0.06963     -0.03592  \n\nlibrary(forecast)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: log(FER2)\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.125861 0.0179801 11.3509 6.763e-06 ***\nBLOCO      3 0.020357 0.0067856  4.2837   0.01655 *  \nResiduals 21 0.033265 0.0015840                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ncheck_heteroscedasticity(aov_fer)\n\nOK: Error variance appears to be homoscedastic (p = 0.658).\n\ncheck_normality(aov_fer)\n\nOK: residuals appear as normally distributed (p = 0.772).\n\nmedias_fer&lt;- emmeans(aov_fer, ~TRAT,)\nmedias_fer\n\n TRAT emmean     SE df lower.CL upper.CL\n 1    -0.452 0.0199 21   -0.493   -0.410\n 2    -0.518 0.0199 21   -0.559   -0.477\n 3    -0.596 0.0199 21   -0.637   -0.554\n 4    -0.641 0.0199 21   -0.683   -0.600\n 5    -0.619 0.0199 21   -0.660   -0.577\n 6    -0.649 0.0199 21   -0.690   -0.607\n 7    -0.607 0.0199 21   -0.648   -0.566\n 8    -0.599 0.0199 21   -0.641   -0.558\n\nResults are averaged over the levels of: BLOCO \nResults are given on the log (not the response) scale. \nConfidence level used: 0.95 \n\npwpm(medias_fer)\n\n         1        2        3        4        5        6        7        8\n1 [-0.452]   0.3105   0.0010   &lt;.0001   0.0002   &lt;.0001   0.0004   0.0007\n2  0.06635 [-0.518]   0.1587   0.0053   0.0314   0.0029   0.0734   0.1245\n3  0.14406  0.07771 [-0.596]   0.7347   0.9903   0.5707   0.9999   1.0000\n4  0.18962  0.12326  0.04556 [-0.641]   0.9909   1.0000   0.9186   0.8058\n5  0.16696  0.10060  0.02290 -0.02266 [-0.619]   0.9547   0.9999   0.9967\n6  0.19729  0.13093  0.05323  0.00767  0.03033 [-0.649]   0.8058   0.6515\n7  0.15544  0.08909  0.01138 -0.03417 -0.01151 -0.04184 [-0.607]   1.0000\n8  0.14777  0.08142  0.00371 -0.04184 -0.01919 -0.04951 -0.00767 [-0.599]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer, Letters=LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6    -0.649 0.0199 21   -0.690   -0.607  A    \n 4    -0.641 0.0199 21   -0.683   -0.600  A    \n 5    -0.619 0.0199 21   -0.660   -0.577  A    \n 7    -0.607 0.0199 21   -0.648   -0.566  AB   \n 8    -0.599 0.0199 21   -0.641   -0.558  AB   \n 3    -0.596 0.0199 21   -0.637   -0.554  AB   \n 2    -0.518 0.0199 21   -0.559   -0.477   BC  \n 1    -0.452 0.0199 21   -0.493   -0.410    C  \n\nResults are averaged over the levels of: BLOCO \nResults are given on the log (not the response) scale. \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula8.html#anova-prod",
    "href": "aula8.html#anova-prod",
    "title": "aula 8",
    "section": "Anova PROD",
    "text": "Anova PROD\n\naov_prod&lt;-lm(PROD~ TRAT + BLOCO,\n             data=soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(agricolae)\ncv.model(aov_prod)\n\n[1] 8.057402\n\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\nlibrary(emmeans)\nmedias_prod &lt;- emmeans(aov_prod, ~TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\nmedias_prod_grupo &lt;- cld(medias_prod, Letters=LETTERS)"
  },
  {
    "objectID": "aula8.html#presentación-de-datos.",
    "href": "aula8.html#presentación-de-datos.",
    "title": "aula 8",
    "section": "Presentación de datos.",
    "text": "Presentación de datos.\n\nlibrary(emmeans)\ndf_prod&lt;- data.frame(medias_prod_grupo)\ndf_prod|&gt;\n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = 'text', x= 1.2, y = 4200,\n           label = 'A')\n\n\n\n\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, 'df.xlsx')"
  },
  {
    "objectID": "aula8.html#importación-de-datos",
    "href": "aula8.html#importación-de-datos",
    "title": "aula 8",
    "section": "Importación de datos",
    "text": "Importación de datos\n\nriego&lt;-gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585')\n\n\navg_riego &lt;- riego |&gt;\n  group_by(Irrigation,day)|&gt;\n  summarize(avg_severity = mean(severity))\n\n\nrdc&lt;-ggplot(avg_riego, aes(x = day, y = avg_severity, color = Irrigation)) +\n  geom_line()\n\n\nrdc"
  },
  {
    "objectID": "aula8.html#visualización-de-los-datos.",
    "href": "aula8.html#visualización-de-los-datos.",
    "title": "aula 8",
    "section": "Visualización de los datos.",
    "text": "Visualización de los datos.\n\nlibrary(epifitter)\ncurve2 &lt;- riego |&gt;\n  group_by(Irrigation, rep)|&gt;\n  summarise(aacpd = AUDPC(day, severity))\ncurve\n\nfunction (expr, from = NULL, to = NULL, n = 101, add = FALSE, \n    type = \"l\", xname = \"x\", xlab = xname, ylab = NULL, log = NULL, \n    xlim = NULL, ...) \n{\n    sexpr &lt;- substitute(expr)\n    if (is.name(sexpr)) {\n        expr &lt;- call(as.character(sexpr), as.name(xname))\n    }\n    else {\n        if (!((is.call(sexpr) || is.expression(sexpr)) && xname %in% \n            all.vars(sexpr))) \n            stop(gettextf(\"'expr' must be a function, or a call or an expression containing '%s'\", \n                xname), domain = NA)\n        expr &lt;- sexpr\n    }\n    if (dev.cur() == 1L && !isFALSE(add)) {\n        warning(\"'add' will be ignored as there is no existing plot\")\n        add &lt;- FALSE\n    }\n    addF &lt;- isFALSE(add)\n    if (is.null(ylab)) \n        ylab &lt;- deparse(expr)\n    if (is.null(from) || is.null(to)) {\n        xl &lt;- xlim %||% if (!addF) {\n            pu &lt;- par(\"usr\")[1L:2L]\n            if (par(\"xaxs\") == \"r\") \n                pu &lt;- extendrange(pu, f = -1/27)\n            if (par(\"xlog\")) \n                10^pu\n            else pu\n        }\n        else c(0, 1)\n        if (is.null(from)) \n            from &lt;- xl[1L]\n        if (is.null(to)) \n            to &lt;- xl[2L]\n    }\n    lg &lt;- if (length(log)) \n        log\n    else if (!addF && par(\"xlog\")) \n        \"x\"\n    else \"\"\n    if (length(lg) == 0) \n        lg &lt;- \"\"\n    if (grepl(\"x\", lg, fixed = TRUE)) {\n        if (from &lt;= 0 || to &lt;= 0) \n            stop(\"'from' and 'to' must be &gt; 0 with log=\\\"x\\\"\")\n        x &lt;- exp(seq.int(log(from), log(to), length.out = n))\n    }\n    else x &lt;- seq.int(from, to, length.out = n)\n    ll &lt;- list(x = x)\n    names(ll) &lt;- xname\n    y &lt;- eval(expr, envir = ll, enclos = parent.frame())\n    if (length(y) != length(x)) \n        stop(\"'expr' did not evaluate to an object of length 'n'\")\n    if (isTRUE(add)) \n        lines(x = x, y = y, type = type, ...)\n    else plot(x = x, y = y, type = type, xlab = xlab, ylab = ylab, \n        xlim = xlim, log = lg, ...)\n    invisible(list(x = x, y = y))\n}\n&lt;bytecode: 0x000001e274caedd8&gt;\n&lt;environment: namespace:graphics&gt;\n\nm_curve&lt;- lm(aacpd ~ Irrigation + factor(rep),\n             data = curve2)\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(agricolae)\ncv.model(m_curve)\n\n[1] 1.097572\n\n#cv.model nos habla del coeficiente de diferencia entre las curvas, que es 1.09% lo vual es bastante bajo"
  },
  {
    "objectID": "aula5.html",
    "href": "aula5.html",
    "title": "Aula5",
    "section": "",
    "text": "Llamado de librerias\n\nlibrary (tidyverse)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(dplyr)\nlibrary(gsheet)\n\n#A continuación se presentará una base de datos de las calificaciones que los estudiantes del cursos FIP 606 recibieron en las dos primeras pruebas cortas realizadas por el profesor Emerson Delponte\n\nDatos &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\n#Vamos a realizar una visualizacion de los datos de manera general:\n\nsummary(Datos)\n\n     prova         pontos           nota       \n Min.   :1.0   Min.   : 6.00   Min.   : 42.90  \n 1st Qu.:1.0   1st Qu.:10.00   1st Qu.: 68.75  \n Median :1.5   Median :12.50   Median : 85.70  \n Mean   :1.5   Mean   :11.91   Mean   : 79.40  \n 3rd Qu.:2.0   3rd Qu.:14.00   3rd Qu.:100.00  \n Max.   :2.0   Max.   :16.00   Max.   :100.00  \n\n\n#Con esto, podemos entender que la nota menor es de 42.9, la mediana esta en 85.70, la media esta en 79.4 y hubieron pesonas con la calificacion mas alta.\n#Primero visualicemos las diferencias entre la primera prueba y la segunda.\n\nDatos|&gt;\n  group_by(prova)|&gt;\n  summarize(mean = mean(nota),\n            median =median(nota),\n            sd_mean= sd(nota),\n            minimo =min(nota),\n            max = max(nota))\n\n# A tibble: 2 × 6\n  prova  mean median sd_mean minimo   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1     1  79.5   85.7    19.0   42.9   100\n2     2  79.3   84.4    19.7   43.8   100\n\n\n#Una vez comparadas, podemos entender que a vista de datos, no existe muchas diferencias entre los resultados de ambas pruebas.\n#Ahora, con esto podemos darnos cuenta de que las calificaciones estuvieron en un promedio mayor a 70 (tomando en cuenta que la desviacion es de +-19 puntos), sin embargo visualizar los datos de manera grafica puede ayudarnos a entender.\n\nDatos |&gt;\n  ggplot(aes(prova,nota))+\n           geom_boxplot(color='black', fill='lightpink')+\n  ylim(0,100)+\n    labs(title= 'Frecuencia de las calificaciones',\n         subtitle = 'FIP606',\n       x= 'Nota',\n       y= 'Densidad')+\n  facet_wrap(~prova,scales = 'free_x')\n\n\n\n\n\n\n\n\n#Observemos esto mismo en un grafico de violin\n\nDatos|&gt;\n  ggplot(aes(x= prova, y = nota))+\n           geom_violin()+\n    labs(title= 'Frecuencia de las calificaciones',\n         subtitle = 'FIP606',\n       x= 'Nota',\n       y= 'Densidad')+\n  theme_dark()+\n  facet_wrap(~prova,scales = 'free_x')\n\n\n\n\n\n\n\n\n#Ahora, observemos las frecuencias de los datos para la primera y segunda prueba.\n\nDatos|&gt;\n  ggplot (aes(x = nota))+\n  geom_histogram(bins = 10,color=\"white\", fill =\"blue\")+\n    labs(title= 'Frecuencia de las calificaciones',\n         subtitle = 'FIP606',\n       x= 'Nota',\n       y= 'Densidad')+\n  xlim(30,110)+\n  facet_wrap(~prova)\n\n\n\n\n\n\n\n\n#Como podemos observar, el grupo con mayor frecuencia esta en el rango de la maxima calificacion.\n#Ahora, para poder concluir este analisis, es importante saber cuantas calificaciones estan entre el rango de 70 a 100, por lo que con el siguiente codigo podemos hacerlo:\n\n#Total de datos prueba 1: 22\n#Total de datos prueba 2: 22\n\nCalificaciones1 &lt;- sum(Datos$nota[Datos$prova == 1] &gt;= 70 & Datos$nota[Datos$prova == 1] &lt;= 100)\nCalificaciones2 &lt;- sum(Datos$nota[Datos$prova == 2] &gt;= 70 & Datos$nota[Datos$prova == 2] &lt;= 100)\n\nprint('Cantidad de estudiantes que pasaron la prueba 1:')\n\n[1] \"Cantidad de estudiantes que pasaron la prueba 1:\"\n\nprint(Calificaciones1)\n\n[1] 16\n\nprint('Cantidad de estudiantes que pasaron la prueba 2:')\n\n[1] \"Cantidad de estudiantes que pasaron la prueba 2:\"\n\nprint(Calificaciones2)\n\n[1] 13\n\nprint(\"Porcentaje de estudiantes que pasaron la prueba 1:\")\n\n[1] \"Porcentaje de estudiantes que pasaron la prueba 1:\"\n\n16/22*100\n\n[1] 72.72727\n\nprint(\"Porcentaje de estudiantes que pasaron la prueba 2:\")\n\n[1] \"Porcentaje de estudiantes que pasaron la prueba 2:\"\n\n13/22*100\n\n[1] 59.09091\n\n\n#Por lo tanto, podemos concluir que para ambas pruebas, mas de la mitad de estudiantes pasaron los examenes cortos.\n#Los estudiantes que pasaron la segunda prueba son menos de los que pasaron la primera prueba."
  },
  {
    "objectID": "aula3.html",
    "href": "aula3.html",
    "title": "aula3",
    "section": "",
    "text": "#Visualizacion\n#Vamos a utilizar la biblioteca ggplot2 para visualizar los conjuntos de datos de la base de datos de roya en unas fincas y jardines con cafe en Etiopia.\n\n#Histograma\n#A continuacion, tenemos un histograma de la incidencia segun la region\n\nlibrary(tidyverse)\ncr&lt;-read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…\n\ncr|&gt;\n  ggplot (aes(x = inc))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n#Histograma tiene una distribucion de las variables segun la respuestas.\n#x es la incidencia en este caso\n# Multimodal significa tener varios picos, es decir que este gráfico puede considerarse un histograma multimodal.\n\nEste histograma demuestra la severidad según la región\n\ncr |&gt;\n  ggplot (aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\n\n\nGrafico de Puntos\nEste es un grafico de dispersion en el cual podremos ver visualmente la interaccion de la severidad con la incidencia.\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n#Summary hace un resúmen de los datos. el $ se utiliza para pedir un resúmen de la incidencia en específico, ignorando el resto de datos.\ncr |&gt;\n  group_by(cultivar)|&gt;\n  summarize(inc_mean = mean(inc),\n            sd_mean= sd(inc))\n\n# A tibble: 3 × 3\n  cultivar inc_mean sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4    5.66\n2 Local        53.4   14.3 \n3 Mixture      31.9   11.2 \n\ncr |&gt;\n  ggplot(aes(inc, sev2))+\n  geom_point()\n\n\n\n\n\n\n\n#la severidad nos sirve mucho, por lo que podemos hacer una prediccion con la incidencia, al ser el valor mas importante\n\n\n\n\n##Boxplot\n#Los gráficos de boxplot pueden utilizarse para realizar visualizaciones rápidas de los datos.\n\ncr|&gt;\n  ggplot (aes(farm,inc))+\n  geom_boxplot()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\n\n#Aquí estamos aplicando la media, la mediana y la desviación estandar de la severidad.\n\ncr |&gt;\nsummarize (sev_med = median(sev2),\n           sev_mean =mean(sev2),\n           sev_sd = sd(sev2))\n\n# A tibble: 1 × 3\n  sev_med sev_mean sev_sd\n    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1    5.95     9.09   9.22\n\n\n#Ahora, trabajaremos con una serie de histogramas que nos permitan ver las diferencias entre regiones y cultivares según la severidad.\n\nlibrary(ggthemes)\ncr |&gt;\n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram(color = \"black\")+\n  facet_grid(region ~ cultivar)+\n  scale_fill_manual(values=(c(\"red\", \"blue\")))+\n  theme_minimal(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  #light es un tema que se coloca.\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\")\n\n\n\n\n\n\n\n  ggsave(\"crl.png\", bg= \"white\")\n\nEl grafico próximo es exactamente igual, solo que se ha cambiado el tema gráfico.\n\nlibrary(ggthemes)\ncr |&gt;\n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram(color = \"white\")+\n  facet_grid(region ~ cultivar, ncol(6))+\n  scale_fill_colorblind()+\n  theme_minimal(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  #light es un tema que se coloca.\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\")\n\n\n\n\n\n\n\n  ggsave(\"crl2.png\", bg= \"white\")\n\n\n#Creacion de subconjuntos\n#Se seleccionan conjuntos especificos.\n#En este caso se filtraron los datos para la region de Oromia, lo que deja 165 lineas en 4 variables, lo mismo con SNNPR.\n#Esto sucede gracias a las funciones select y filter, estos son de la biblioteca dplyr.\n\n#Filtrado region Oromia\ncr_oromia&lt;- cr |&gt;\n  select (farm, region, sev2, cultivar)|&gt;\n  filter (region == \"Oromia\")\n#Filtrado region SNNPR\ncr_pr&lt;- cr |&gt;\n  select (farm, region, sev2, cultivar)|&gt;\n  filter (region == \"SNNPR\")\n\n##Visualizacion de los subconjuntos\nSe utilizaran graficos ggplot para cada subconjunto.\n\np1 &lt;-cr_oromia |&gt;\n  ggplot(aes(cultivar, sev2,\n             fill=cultivar))+\n         geom_boxplot()+\n  scale_fill_brewer()+\n  labs(y= \" \", title = \"Oromia\")+\n  coord_flip()\np2&lt;- cr_pr |&gt;\n  ggplot(aes(cultivar, sev2,\n             fill= cultivar))+\n         geom_boxplot()+\n  scale_fill_brewer()+\n  labs(y= \"Severity (%)\", title = \"SNNPR\")+\n  coord_flip()\np1\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\n#Queremos colocar ambos graficos uno al lado del otro, utilizaremos la biblioteca patchwork\n\n#Aquí es importante saber que con la librería patchwork, podemos unir diferentes componentes gráficos en una sola imágen.\n\nlibrary(patchwork)\n\n(p1/p2)+\n  plot_layout(guides = 'collect')+\n  plot_annotation(title = \"Coffee rust in Ethiopia\",\n                  caption = \"source: Del Ponte (2022)\",\n                  tag_levels = 'A')\n\n\n\n\n\n\n\n# En vez de +, se puede colocar | o /, para colocarlo en otros lados.\n#tambien se pueden combinar como p1 (p1+p2) para tener uno grande arriba y 2 abajo\nggsave(\"patch1.png\", width = 6, height = 10)\n\n\n\n\n#Inserciones de graficos sobre graficos\n#Se pueden colocar graficos insertandolos sobre otros.\n\np3 &lt;- cr_oromia |&gt;\n  ggplot(aes(x=sev2))+\n  geom_histogram()\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)"
  },
  {
    "objectID": "aula11.html",
    "href": "aula11.html",
    "title": "aula 11",
    "section": "",
    "text": "library(remotes)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\n\n\nworld&lt;-ne_countries()\nBRA&lt;- ne_states(country = 'Brazil',\n                returnclass = \"sf\")\nlibrary(tidyverse)\nggplot(BRA)+\n  geom_sf(fill = 'white')\n\n\n\n\n\n\n\nMG &lt;- BRA |&gt;\n  filter(name_en == 'Minas Gerais')\n\n\nlibrary(r4pde)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(ggspatial)\nsbr&lt;-RustSoybean\n\nbra&lt;-ggplot(BRA)+\n  geom_sf(fill = \"black\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_sf(data=MG, fill = 'white')+\n  geom_point(data = sbr, aes(longitude, latitude),\n            color = 'white')+\n            theme_map()+\n  annotation_north_arrow(which_north = \"grid\")\n\n\nlibrary(plotly)\nggplotly(bra)\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet() |&gt;\n  addProviderTiles(providers$Esri.NatGeoWorldMap)|&gt;\n  setView(lng =-42.8825, lat = -20.7546, zoom = 5)\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet(sbr) |&gt;\n  addTiles()|&gt;\n  setView(lng =-42.8825, lat = -20.7546, zoom = 15)|&gt;\n  addCircleMarkers(radius=\"severity\")\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet(sbr) |&gt;\n  addTiles()|&gt;\n  setView(lng =-42.8825, lat = -20.7546, zoom = 5)|&gt;\n  addCircleMarkers(radius=1)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "aula1.html",
    "href": "aula1.html",
    "title": "Aula1",
    "section": "",
    "text": "Clase número 1.\nSe realizan comentarios por medio de utilizar “#”\nLo primero a entender es los tipos de archivos que podemos generar\nPrimero hay que hacer un proyecto, luego abrimos puede ser un documento R notebook o un Quarto.\nPrimero se debe abrir un “quote” donde se establezca que estamos colocando programación de R.\n\nprint(\"Hello, world.\")\n\n[1] \"Hello, world.\"\n\n\nEn estos mismos cuadros de programación, podemos empezar a definir cuáles son nuestras bases de datos, nuestros datos dentro de las bases e incluso llamar bibliotecas con las cuales podemos analizar nuestros datos.\nEn el siguiente ejemplo podemos observar como a X, Y y Z se les estan atribuyendo valores.\n\nx &lt;- 10\ny &lt;- x * 10\nz &lt;- x * y\nx &lt;- 10\n\n\n\nAhora, podemos observar como un data frame está siendo creado.\n\nz&lt;- x^3\nA &lt;- c(1:10)\nB&lt;- c(11:20)\nB\n\n [1] 11 12 13 14 15 16 17 18 19 20\n\ndf&lt;- data.frame(A, B)\ndf\n\n    A  B\n1   1 11\n2   2 12\n3   3 13\n4   4 14\n5   5 15\n6   6 16\n7   7 17\n8   8 18\n9   9 19\n10 10 20\n\nB&lt;- c(11:20)\n\nis.data.frame(A) \n\n[1] FALSE\n\nis.data.frame(B)\n\n[1] FALSE\n\n\n\n\nEn la siguiente línea de códigos, podemos visualizar como se abren las librerías.\n\nlibrary(agricolae)\n\ndates &lt;- c(14,21,28) #days\n\n#example 1 : evaluation - vector\n\nevaluation &lt;- c(40, 80, 90)\n\naudpc(evaluation, dates)\n\nevaluation \n      1015 \n\nlibrary(epifitter)\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "aula2.html",
    "href": "aula2.html",
    "title": "aula2",
    "section": "",
    "text": "En esta clase se va a ver cómo abrir bases de datos desde excel, ya sea en el computador así como en un link en específico.\nPrimero, veamos una lista de librerías que pueden ser de interés para todos nosotros:\n\nlibrary(agricolae)\nlibrary(agridat)\nlibrary(ec50estimator)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(ggplot2)\n\nComo podemos observar, estamos llamando una base de datos que originalmente se llama “corn” y le pusimos el nombre de “dat”.\n\nlibrary(agricolae)\ndat&lt;- data(corn)\n\nVamos a traer la librería para leer exceles y se les coloca un nombre.\n\ndf1&lt;- multi_isolate\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21&lt;- read_excel(\"dados-diversos.xlsx\", sheet= (\"escala\"))\n                  \n    #Se puede colocar el numero de tabla es decir, en vez de sheet escala y todo eso, simplemente colocar 2 e igual coloca bien.\n\n\nlibrary(tidyverse)\ndf3&lt;-read_csv(\"dados-diversos.csv\")\n\n#Aquí estamos viendo como abrimos una hoja de datos desde un link de google docs.\n\nlibrary(gsheet)\n\ndf4&lt;-gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\n##Gráficos.\n#La librería de ggplot2 nos puede ayudar para convertir rápidamente estas bases de datos en formas gráficas para entender visualmente mejor la distribuición de estos datos.\n\nlibrary(ggplot2)\ng1&lt;-df4 |&gt;\n  ggplot(aes (trat, comp))+\n  geom_jitter(width = 0.05,\n               color=\"black\",\n              shape = 2,\n              size=3)+\n  geom_boxplot(outlier.color = NA,\n                  fill = \"green\")+\n  labs(x=\"Tratamento\",\n       y= \"Comprimento(mm)\",\n      title= \"meu primeiro ggplot\",\n      caption=\"Fonte: Dados diversos\")+\n  scale_y_continuous(limits = c(0,20),\n                     n.breaks = 10)#tambien se puede usar ylim(0,10)\n\ng1\n\n\n\n\n\n\n\n#Se puede colocar + theme_classic() para poder colocar un diseno más bonito.\n# Librería ggthemes da más temas bonitos"
  },
  {
    "objectID": "aula4.html",
    "href": "aula4.html",
    "title": "aula4",
    "section": "",
    "text": "#Gracias al paquete datapasta, podemos copiar y pegar bases de datos como si fueran bases de datos en codigo python utilizando paste as tribble o dataframe.\n\nlibrary(datapasta)\ndat &lt;- tibble::tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,  12.5,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,  13.2,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,  10.8,\n      \"Mg2\",   8L,   9.5,\n      \"Mg2\",   9L,  10.8,\n      \"Mg2\",  10L,  10.4,\n  \"control\",   1L, 13.72,\n  \"control\",   2L, 15.91,\n  \"control\",   3L,  15.7,\n  \"control\",   4L,  14.2,\n  \"control\",   5L,  15.9,\n  \"control\",   6L, 16.54,\n  \"control\",   7L,    18,\n  \"control\",   8L,  14.4,\n  \"control\",   9L, 16.41,\n  \"control\",  10L,    16\n  )\ndat\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\ncomp&lt;-data.frame(check.names = FALSE,\n                `9` = c(12.5,10,8,13.2,11,10.8,\n                        9.5,10.8,10.4,13.72,15.91,15.7,\n                        14.2,15.9,16.54,\n                        18,14.4,16.41,16))\n\ncomp\n\n       9\n1  12.50\n2  10.00\n3   8.00\n4  13.20\n5  11.00\n6  10.80\n7   9.50\n8  10.80\n9  10.40\n10 13.72\n11 15.91\n12 15.70\n13 14.20\n14 15.90\n15 16.54\n16 18.00\n17 14.40\n18 16.41\n19 16.00\n\n\n#Desde una pagina web podemos obtener datos, copiar las tablas y pegarlas como data frame listas, asi como en el siguiente ejemplo tomado de la pagina web\n\npoblaciones &lt;- tibble::tribble(\n  ~Fecha, ~Densidad,    ~Hombres,    ~Mujeres,  ~Población,\n   2022L,      102L,          NA,          NA, \"5.229.000\",\n   2021L,      101L, \"2.578.741\", \"2.575.216\", \"5.180.000\",\n   2020L,      100L, \"2.564.622\", \"2.558.483\", \"5.128.000\",\n   2019L,       99L, \"2.546.376\", \"2.538.156\", \"5.075.000\",\n   2018L,       98L, \"2.525.472\", \"2.515.262\", \"5.022.000\",\n   2017L,       97L, \"2.502.859\", \"2.490.983\", \"4.966.000\",\n   2016L,       96L, \"2.479.289\", \"2.465.916\", \"4.909.000\",\n   2015L,       95L, \"2.455.070\", \"2.440.173\", \"4.851.000\",\n   2014L,       94L, \"2.430.257\", \"2.414.032\", \"4.793.000\",\n   2013L,       93L, \"2.404.428\", \"2.387.107\", \"4.733.000\",\n   2012L,       91L, \"2.377.400\", \"2.359.193\", \"4.673.000\",\n   2011L,       90L, \"2.349.468\", \"2.330.459\", \"4.613.000\",\n   2010L,       89L, \"2.321.021\", \"2.301.231\", \"4.554.000\",\n   2009L,       87L, \"2.291.917\", \"2.271.211\", \"4.469.000\",\n   2008L,       86L, \"2.261.818\", \"2.240.104\", \"4.404.000\",\n   2007L,       85L, \"2.231.315\", \"2.208.704\", \"4.340.000\",\n   2006L,       84L, \"2.200.829\", \"2.177.342\", \"4.279.000\",\n   2005L,       82L, \"2.170.068\", \"2.145.820\", \"4.215.000\",\n   2004L,       81L, \"2.138.782\", \"2.114.018\", \"4.152.000\",\n   2003L,       80L, \"2.106.901\", \"2.081.709\", \"4.086.000\",\n   2002L,       79L, \"2.074.083\", \"2.048.540\", \"4.022.000\",\n   2001L,       77L, \"2.039.504\", \"2.013.719\", \"3.953.000\",\n   2000L,       75L, \"2.002.605\", \"1.976.587\", \"3.810.000\",\n   1999L,       75L, \"1.963.914\", \"1.937.516\", \"3.838.000\",\n   1998L,       73L, \"1.924.069\", \"1.897.353\", \"3.747.000\",\n   1997L,       72L, \"1.883.219\", \"1.856.202\", \"3.657.000\",\n   1996L,       70L, \"1.841.732\", \"1.814.502\", \"3.565.000\",\n   1995L,       68L, \"1.800.079\", \"1.772.777\", \"3.470.000\",\n   1994L,       66L, \"1.758.226\", \"1.730.927\", \"3.373.000\",\n   1993L,       64L, \"1.716.205\", \"1.689.167\", \"3.275.000\",\n   1992L,       62L, \"1.674.268\", \"1.647.671\", \"3.191.000\",\n   1991L,       61L, \"1.632.684\", \"1.606.731\", \"3.122.000\",\n   1990L,       60L, \"1.591.754\", \"1.566.500\", \"3.051.000\",\n   1989L,       58L, \"1.551.852\", \"1.527.149\", \"2.977.000\",\n   1988L,       57L, \"1.512.773\", \"1.488.688\", \"2.901.000\",\n   1987L,       55L, \"1.473.947\", \"1.450.648\", \"2.824.000\",\n   1986L,       54L, \"1.435.166\", \"1.412.683\", \"2.746.000\",\n   1985L,       52L, \"1.396.589\", \"1.374.874\", \"2.666.000\",\n   1984L,       51L, \"1.358.572\", \"1.337.628\", \"2.588.000\",\n   1983L,       49L, \"1.321.306\", \"1.301.226\", \"2.514.000\",\n   1982L,       48L, \"1.285.040\", \"1.265.740\", \"2.443.000\",\n   1981L,       46L, \"1.249.954\", \"1.231.380\", \"2.372.000\",\n   1980L,       45L, \"1.216.189\", \"1.198.113\", \"2.302.000\",\n   1979L,       46L, \"1.183.549\", \"1.165.709\", \"2.349.258\",\n   1978L,       45L, \"1.151.907\", \"1.134.303\", \"2.286.210\",\n   1977L,       44L, \"1.121.564\", \"1.104.065\", \"2.225.630\",\n   1976L,       42L, \"1.092.518\", \"1.075.026\", \"2.167.544\",\n   1975L,       41L, \"1.064.693\", \"1.047.158\", \"2.111.850\",\n   1974L,       40L, \"1.037.979\", \"1.020.256\", \"2.058.235\",\n   1973L,       39L, \"1.012.096\",   \"994.152\", \"2.006.247\",\n   1972L,       38L,   \"986.856\",   \"968.691\", \"1.955.547\",\n   1971L,       37L,   \"961.980\",   \"943.506\", \"1.905.486\",\n   1970L,       36L,   \"937.247\",   \"918.450\", \"1.855.697\",\n   1969L,       35L,   \"912.558\",   \"893.410\", \"1.805.968\",\n   1968L,       34L,   \"887.868\",   \"868.465\", \"1.756.333\",\n   1967L,       33L,   \"862.766\",   \"843.295\", \"1.706.062\",\n   1966L,       32L,   \"837.030\",   \"817.588\", \"1.654.619\",\n   1965L,       31L,   \"811.096\",   \"791.641\", \"1.602.736\",\n   1964L,       30L,   \"785.063\",   \"765.598\", \"1.550.661\",\n   1963L,       29L,   \"758.976\",   \"739.670\", \"1.498.647\",\n   1962L,       28L,   \"733.055\",   \"713.982\", \"1.447.037\",\n   1961L,       27L,   \"707.489\",   \"688.649\", \"1.396.138\",\n   1960L,       26L,   \"682.455\",   \"663.847\", \"1.346.302\"\n  )\n#Con esto podemos ordenar los datos de menor a mayor\nordered &lt;- poblaciones[order(poblaciones$Fecha), ]\npoblaciones\n\n# A tibble: 63 × 5\n   Fecha Densidad Hombres   Mujeres   Población\n   &lt;int&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    \n 1  2022      102 &lt;NA&gt;      &lt;NA&gt;      5.229.000\n 2  2021      101 2.578.741 2.575.216 5.180.000\n 3  2020      100 2.564.622 2.558.483 5.128.000\n 4  2019       99 2.546.376 2.538.156 5.075.000\n 5  2018       98 2.525.472 2.515.262 5.022.000\n 6  2017       97 2.502.859 2.490.983 4.966.000\n 7  2016       96 2.479.289 2.465.916 4.909.000\n 8  2015       95 2.455.070 2.440.173 4.851.000\n 9  2014       94 2.430.257 2.414.032 4.793.000\n10  2013       93 2.404.428 2.387.107 4.733.000\n# ℹ 53 more rows\n\n\nAhora, con esta nueva base de datos podemos ver la incidencia en una enfermedad, colocando anotaciones acerca de cuál es cada línea.\n\nlibrary(tidyverse)\npepper&lt;-tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\")|&gt;\n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\",\n           x= 12,\n           y= 0.75,\n           label = \"1\")+\n  annotate(geom = \"text\",\n           x= 25,\n           y= 0.75,\n           label = \"2\")\n\n\n\n\n\n\n\n\n\n\n#Con count podemos hacer un conteo según lo que necesitemos, en este caso, se contaron los datos según fueran una región y una zona específica.\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\ncr |&gt;\n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60"
  },
  {
    "objectID": "aula4.html#tabla-de-contingencia.",
    "href": "aula4.html#tabla-de-contingencia.",
    "title": "aula4",
    "section": "",
    "text": "#Con count podemos hacer un conteo según lo que necesitemos, en este caso, se contaron los datos según fueran una región y una zona específica.\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\ncr |&gt;\n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60"
  },
  {
    "objectID": "aula6.html",
    "href": "aula6.html",
    "title": "aula 6 y 7",
    "section": "",
    "text": "library(gsheet)\nmg&lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\nlibrary(tidyverse)\nmg |&gt;\n  ggplot(aes(trat, comp))+\n  geom_boxplot()\nParametrico\nEl test T tiene Paired (TRUE) y Non Paired (FALSE) Es cuando tengo variables dependientes o independientes.\nLuego tenemos variancias Var.test, si este da menor a 0,05 tenemos Var.Equal = False.\nNo parametrico\nWillcox.test (Paired = True False) Este solo se usa para variables dependientes.\nMannWhitney es para variables independientes.\nmg2&lt;-mg |&gt;\n  pivot_wider (names_from = trat,\n               values_from = comp)\nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\nteste1&lt;-t.test(mg2$Mg2, mg2$control,\n       var.equal=TRUE)\nteste1\n\n\n    Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 18, p-value = 1.863e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.486839 -3.829161\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n#Puede ser FALSE tambien, esto se cambia para que las varianzas sean heterogeneas, esto depende del test de varianzas\n\n# hipotesis nula es normalidad en el shapiro.\nhist(mg2$control)\n\n\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\nwilcox.test(mg2$Mg2, mg2$control,\n       paired= FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  mg2$Mg2 and mg2$control\nW = 0, p-value = 0.0001817\nalternative hypothesis: true location shift is not equal to 0\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n#Todo esto se usa para revisar si la Hipotesis nula de la propuesta inicial puede ser rechazada. Este es un test parametrico al haber normalidad.\nqqnorm(mg2$control)\nqqline(mg2$control)\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Two Sample t-test testing the difference between mg2$Mg2 and mg2$control\n(mean of x = 10.52, mean of y = 15.68) suggests that the effect is negative,\nstatistically significant, and large (difference = -5.16, 95% CI [-6.49,\n-3.83], t(18) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.10, -2.16])"
  },
  {
    "objectID": "aula6.html#alternativa-1---transformacion.",
    "href": "aula6.html#alternativa-1---transformacion.",
    "title": "aula 6 y 7",
    "section": "Alternativa 1 - Transformacion.",
    "text": "Alternativa 1 - Transformacion.\n\nm2&lt;- lm(count ~ spray,\n         data = insecticida)\ninsecticida2 &lt;- insecticida |&gt;\n  mutate(count2= sqrt(count))\ninsecticida2 |&gt;\n  ggplot(aes(spray,count2))+\n           geom_boxplot()\n\n\n\n\n\n\n\nm2&lt;- lm(count2 ~ spray,\n         data = insecticida2)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = insecticida2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\n\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~ spray,\n              data = insecticida2)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary (emmeans)\nm2_medias&lt;-emmeans(m2, ~ spray)\nm2_medias\n\n spray emmean    SE df lower.CL upper.CL\n A       3.76 0.181 66    3.399     4.12\n B       3.88 0.181 66    3.514     4.24\n C       1.24 0.181 66    0.883     1.61\n D       2.16 0.181 66    1.802     2.53\n E       1.81 0.181 66    1.447     2.17\n F       4.02 0.181 66    3.656     4.38\n\nConfidence level used: 0.95 \n\nplot(m2_medias)\n\n\n\n\n\n\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n\n\n\n\n#El test de anova demuestra que por lo menos uno de los grupos demuestra diferencia de los otros.\n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\n\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n#Transformación de box-cox y(lambda)= (x^lambda-1)/lambda\nlibrary (MASS)\n\nb&lt;-boxcox(lm(insecticida$count+0.1~1))\n\n\n\n\n\n\n\n#calcular lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n#hacer la formula\ninsecticida$count3 &lt;- (insecticida$count ^ lambda -1) /lambda\ninsecticida$count3\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n#Es el dato que se va a utilizar para la transformacion\n#Si lambda es 0.5 es igual que hacer la raiz cuadrada."
  },
  {
    "objectID": "aula6.html#alternativa-2---no-parametrico",
    "href": "aula6.html#alternativa-2---no-parametrico",
    "title": "aula 6 y 7",
    "section": "Alternativa 2 - no parametrico",
    "text": "Alternativa 2 - no parametrico\n\nlibrary(agricolae)\nkruskal.test(count ~ spray,\n             data = insecticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n#las medias no son iguales, pues se rechaza la hipotesis nula\nKAgric&lt;-kruskal(insecticida$count,\n        insecticida$spray,\n        group = TRUE)\n#El group es para colocar los grupos con el test de Fischer.\nKAgric\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted            name.t ntr alpha\n  Kruskal-Wallis      none insecticida$spray   6  0.05\n\n$means\n  insecticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA         14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB         15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC          2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD          4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE          3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF         16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  insecticida$count groups\nF          55.62500      a\nB          54.83333      a\nA          52.16667      a\nD          25.58333      b\nE          19.33333     bc\nC          11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n#El metodo no parametrico dio la misma respuesta que el metodo transformado para el metodo parametrico."
  },
  {
    "objectID": "aula6.html#alternativa-3-glms",
    "href": "aula6.html#alternativa-3-glms",
    "title": "aula 6 y 7",
    "section": "Alternativa 3 GLMs",
    "text": "Alternativa 3 GLMs\n\nm4 &lt;- glm(count~spray,\n          family= poisson,\n          data = insecticida)\n\n#La distribucion se ajusta bien a poisson por la numerica discreta, al testar esto, se da una desviacion Dice que el valor de Anova es significativo, diciendo que uno dio diferente a los otros.\n#Al hacerse todo l\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = insecticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\nm4_medias&lt;- emmeans(m4,~spray,\n                    type = 'response')\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\n#Asymp habla de que todas las respuestas estan en este rango\n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula6.html#anova-factorial",
    "href": "aula6.html#anova-factorial",
    "title": "aula 6 y 7",
    "section": "Anova Factorial",
    "text": "Anova Factorial\n\nlibrary(gsheet)\nli &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672')\n\n#Severidad en funcion a tratamientos\nli |&gt;\n  ggplot(aes(factor(dose), severity, color = factor (dose)))+\n  geom_jitter(width=0.1)+\n  facet_wrap(~treat)\n\n\n\n\n\n\n\n\n##Modelo factorial (twoway anova)\n\nmf &lt;- lm(severity ~ treat*factor(dose),\n         data= li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#podemos ver que la interaccion entre dosis y tratamiento no es significativa.\n#Las letras mayusculas comparan Los pesticidas y la minuscula compara los dosajes.\n#Antes de todo esto, debemos testar las premisas.\n\nplot(simulateResiduals(mf))\n\n\n\n\n\n\n\ncheck_normality(mf)\n\nWarning: Non-normality of residuals detected (p = 0.011).\n\ncheck_heteroscedasticity(mf)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n#Viendo los dosajes de los tratamientos\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#Viendo los pesticidas segun el tratamiento\nmf_medias2 &lt;- emmeans(mf, ~ treat | dose)\ncld(mf_medias2)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  1    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   2   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  1    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula9.html",
    "href": "aula9.html",
    "title": "aula9",
    "section": "",
    "text": "Cada híbrido está dentro de cada bloque, el bloque se aleatorizó dentro de cada bloque.\nSe sortean los tratamientos del híbrido y los del método.\nSe sortean estos híbridos dentro de cada bloque.\nEs una parcela subdivida. ¿Cuándo es una parcela sub-sub dividida? Cuando hay 3 factores.\nNuestro modelo estadístico va a ser diferente, no es híbrido vs método+ bloque, se debe utilizar el valor b o utilizar un modelo mixto (mixtura entre un factor fijo y uno aleatorio). Ese es el modelo mixto, es un paquete diferente para estructurar esta situación (efecto aleatorio del híbrido).\n\n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(DHARMa)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(emmeans)\nmilho &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759')\n\n\n\n\n\nmilho |&gt;\n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, alpha=0.2)+\n  facet_wrap(~hybrid)+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color = 'pink')\n\n\n\n\n\n\n\n\n\nlibrary(lme4)\n\nmilho&lt;-milho|&gt;\n  mutate(block = as.factor(block))\nmix2&lt;- lmer(index ~ hybrid*method + block+\n              (1|block/hybrid), data = milho)\n\nanova(mix2)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 262.548  52.510  3.1194\nmethod           1  79.053  79.053  4.6963\nblock            3   3.630   1.210  0.0719\nhybrid:method    5 266.064  53.213  3.1612\n\nlibrary(car)\n\n1|block/hybrid indica la función (con efecto aleatorio). El resultado para la interacción entre híbrido y method es significativa.\n\n\n\nlibrary(performance)\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\nsimulate_residuals(mix2)\n\nSimulated residuals from a model of class `lmerMod` based on 250\n  simulations. Use `check_residuals()` to check uniformity of residuals or\n  `residuals()` to extract simulated residuals. It is recommended to refer\n  to `?DHARMa::simulateResiudals` and `vignette(\"DHARMa\")` for more\n  information about different settings in particular situations or for\n  particular models.\n\n\n\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\n\n\n\n\nhist(residuals(mix2))"
  },
  {
    "objectID": "aula9.html#pudrición-de-maíz.",
    "href": "aula9.html#pudrición-de-maíz.",
    "title": "aula9",
    "section": "",
    "text": "Cada híbrido está dentro de cada bloque, el bloque se aleatorizó dentro de cada bloque.\nSe sortean los tratamientos del híbrido y los del método.\nSe sortean estos híbridos dentro de cada bloque.\nEs una parcela subdivida. ¿Cuándo es una parcela sub-sub dividida? Cuando hay 3 factores.\nNuestro modelo estadístico va a ser diferente, no es híbrido vs método+ bloque, se debe utilizar el valor b o utilizar un modelo mixto (mixtura entre un factor fijo y uno aleatorio). Ese es el modelo mixto, es un paquete diferente para estructurar esta situación (efecto aleatorio del híbrido)."
  },
  {
    "objectID": "aula9.html#parcela-subdividida",
    "href": "aula9.html#parcela-subdividida",
    "title": "aula9",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(DHARMa)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(emmeans)\nmilho &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759')"
  },
  {
    "objectID": "aula9.html#index",
    "href": "aula9.html#index",
    "title": "aula9",
    "section": "",
    "text": "milho |&gt;\n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, alpha=0.2)+\n  facet_wrap(~hybrid)+\n  stat_summary(fun.data='mean_cl_boot', size=0.5, color = 'pink')\n\n\n\n\n\n\n\n\n\nlibrary(lme4)\n\nmilho&lt;-milho|&gt;\n  mutate(block = as.factor(block))\nmix2&lt;- lmer(index ~ hybrid*method + block+\n              (1|block/hybrid), data = milho)\n\nanova(mix2)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 262.548  52.510  3.1194\nmethod           1  79.053  79.053  4.6963\nblock            3   3.630   1.210  0.0719\nhybrid:method    5 266.064  53.213  3.1612\n\nlibrary(car)\n\n1|block/hybrid indica la función (con efecto aleatorio). El resultado para la interacción entre híbrido y method es significativa.\n\n\n\nlibrary(performance)\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\nsimulate_residuals(mix2)\n\nSimulated residuals from a model of class `lmerMod` based on 250\n  simulations. Use `check_residuals()` to check uniformity of residuals or\n  `residuals()` to extract simulated residuals. It is recommended to refer\n  to `?DHARMa::simulateResiudals` and `vignette(\"DHARMa\")` for more\n  information about different settings in particular situations or for\n  particular models.\n\n\n\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\n\n\n\n\nhist(residuals(mix2))"
  },
  {
    "objectID": "aula9.html#primer-orden-modelo-linear",
    "href": "aula9.html#primer-orden-modelo-linear",
    "title": "aula9",
    "section": "Primer orden (Modelo linear)",
    "text": "Primer orden (Modelo linear)\n\nlm2 &lt;- lm(nplants ~trat,\n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\nAIC(lm2)\n\n[1] 194.9597\n\n\n\nexp2$trat2 &lt;- exp2$trat^2\n\nlm3 &lt;- lm(nplants ~trat + trat2,\n          data = exp2)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\n\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nConclusion: EL r2 se explica mejor con la regresion cuadratica que con la linear.\nSegun AIC tambien el modelo cuadratico explica mejor la variacion (diferencia de 43% a 49%), entre menor es mejor,\nY= 66,3 - 1,77 x TRAT + 0,02 x TRAT^2\n\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\nSe puede ver los intervalos de confianza para cada punto, ajustando segun lo que calculo abajo, para dar un R^2.\ngrau 1 = linear.\nGrau 2= cuadratico, modelino curvilinear.\ngrau 3 = cubica, no tiene una explicacion biologica por lo que casi no se utiliza para esta aumentar entre dos tractos."
  },
  {
    "objectID": "aula9.html#filtrar-isolado-186",
    "href": "aula9.html#filtrar-isolado-186",
    "title": "aula9",
    "section": "Filtrar Isolado 186",
    "text": "Filtrar Isolado 186\n\nlibrary(drc)\n\nisolado186 &lt;- pyra2 |&gt; \n   filter(code == \"186\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado186,\n            fct = W1.3())\n\nAIC(drc1)\n\n[1] 20.97861\n\n\n\nplot(drc1)\n\n\n\n\n\n\n\n\nSi la estimativa fuera mas alta, es mas sensible al fungicida.\nSi la estimativa (Estimate) fuera mas baja, es menos sensible al fungicida.\nEntre menor es el AIC, mejor."
  }
]